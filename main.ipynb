{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "LXTj8y_225-_",
    "outputId": "76ece093-55a9-4fbb-ace9-274309953099",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clonage dans 'MRI_Scoring'...\n",
      "remote: Enumerating objects: 37, done.\u001b[K\n",
      "remote: Counting objects: 100% (37/37), done.\u001b[K\n",
      "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
      "remote: Total 37 (delta 9), reused 30 (delta 5), pack-reused 0\u001b[K\n",
      "DÃ©paquetage des objets: 100% (37/37), fait.\n",
      "[Errno 2] No such file or directory: '/content/MRI_Scoring'\n",
      "/home/brice/Documents/3A/kaggle/challenge_JFR\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-47fa73e1b678>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'git clone https://github.com/bricerauby/MRI_Scoring.git'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/MRI_Scoring'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip3 install -r requirements.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "# !git clone https://github.com/bricerauby/MRI_Scoring.git\n",
    "# %cd /content/MRI_Scoring\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# !pip3 install -r requirements.txt\n",
    "# assert os.environ['COLAB_TPU_ADDR']\n",
    "# TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "id": "9MwojvMv6-oD",
    "outputId": "70b8b6af-8cb9-4988-9319-181b2b04e209",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import src.utils\n",
    "import src.model\n",
    "import numpy as np \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def parse_fn(example):\n",
    "    \"Parse TFExample records and perform simple data augmentation.\"\n",
    "    example_fmt = {\n",
    "        'age': tf.io.FixedLenFeature((), tf.int64, -1),\n",
    "        'Sequence_id': tf.io.FixedLenFeature((), tf.string, \"\"),\n",
    "        'EDSS': tf.io.FixedLenFeature((), tf.float32, 0.),\n",
    "        'examination_date': tf.io.FixedLenFeature((), tf.string, \"\"),\n",
    "        'serie_description': tf.io.FixedLenFeature((), tf.string, \"\"),\n",
    "        'h': tf.io.FixedLenFeature((), tf.int64, 0),\n",
    "        'w': tf.io.FixedLenFeature((), tf.int64, 0),\n",
    "        'd': tf.io.FixedLenFeature((), tf.int64, 0),\n",
    "        'r_h': tf.io.FixedLenFeature((), tf.float32, 0),\n",
    "        'r_w': tf.io.FixedLenFeature((), tf.float32, 0),\n",
    "        'r_d': tf.io.FixedLenFeature((), tf.float32, 0),\n",
    "        'image_raw':  tf.io.FixedLenFeature((), tf.string, \"\")\n",
    "    }\n",
    "    parsed = tf.parse_single_example(example, example_fmt)\n",
    "    image = tf.decode_raw(parsed['image_raw'],out_type=tf.float64)\n",
    "    image = tf.reshape(image, shape=(parsed['h'],\n",
    "                                     parsed['w'],\n",
    "                                     parsed['d'],\n",
    "                                     1) )\n",
    "\n",
    "    return image, parsed[\"EDSS\"]\n",
    "\n",
    "def train_input_fn(batch_size=8, buffer_size=8*1024*1024, prefetch_buffer_size=2, num_workers=8):\n",
    "    files = tf.data.Dataset.list_files(\"data/tf_records/train_set_*.tfrecords\")\n",
    "    dataset = files.apply(tf.contrib.data.parallel_interleave(tf.data.TFRecordDataset, \n",
    "                                                              cycle_length=num_workers))\n",
    "    dataset = dataset.shuffle(buffer_size=buffer_size)\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.map(map_func=parse_fn, num_parallel_calls=num_workers)\n",
    "    dataset = dataset.batch(batch_size=batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=prefetch_buffer_size)\n",
    "    return dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = train_input_fn()\n",
    "model = src.model.dumb_model()\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss= 'categorical_crossentropy',\n",
    "  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(dataset, epochs=1, steps_per_epoch=100)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
