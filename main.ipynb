{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "id": "9MwojvMv6-oD",
    "outputId": "70b8b6af-8cb9-4988-9319-181b2b04e209",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# import src.utils\n",
    "import src.model\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import os\n",
    "import json \n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def parse_fn(example):\n",
    "    \"Parse TFExample records and perform simple data augmentation.\"\n",
    "    example_fmt = {\n",
    "        'age': tf.io.FixedLenFeature((), tf.int64, -1),\n",
    "        'Sequence_id': tf.io.FixedLenFeature((), tf.string, \"\"),\n",
    "        'EDSS': tf.io.FixedLenFeature((), tf.float32, 0.),\n",
    "        'examination_date': tf.io.FixedLenFeature((), tf.string, \"\"),\n",
    "        'serie_description': tf.io.FixedLenFeature((), tf.string, \"\"),\n",
    "        'h': tf.io.FixedLenFeature((), tf.int64, 0),\n",
    "        'w': tf.io.FixedLenFeature((), tf.int64, 0),\n",
    "        'd': tf.io.FixedLenFeature((), tf.int64, 0),\n",
    "        'r_h': tf.io.FixedLenFeature((), tf.float32, 0),\n",
    "        'r_w': tf.io.FixedLenFeature((), tf.float32, 0),\n",
    "        'r_d': tf.io.FixedLenFeature((), tf.float32, 0),\n",
    "        'image_raw':  tf.io.FixedLenFeature((), tf.string, \"\")\n",
    "    }\n",
    "    parsed = tf.parse_single_example(example, example_fmt)\n",
    "    image = tf.decode_raw(parsed['image_raw'],out_type=tf.int16)\n",
    "    image = tf.reshape(image, shape=(parsed['h'],\n",
    "                                     parsed['w'],\n",
    "                                     parsed['d'],\n",
    "                                     1) )\n",
    "\n",
    "    return image, parsed[\"EDSS\"]\n",
    "\n",
    "def input_fn(path_to_tf, mode, batch_size=1, buffer_size=1, prefetch_buffer_size=1, num_workers=8):\n",
    "    files = tf.data.Dataset.list_files(os.path.join(path_to_tf, '{}_set_*.tfrecords'.format(mode)))\n",
    "    dataset = files.apply(tf.contrib.data.parallel_interleave(tf.data.TFRecordDataset, \n",
    "                                                              cycle_length=num_workers))\n",
    "    dataset = dataset.shuffle(buffer_size=buffer_size)\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.map(map_func=parse_fn, num_parallel_calls=num_workers)\n",
    "    dataset = dataset.batch(batch_size=batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=prefetch_buffer_size)\n",
    "    return dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/envs/tfenv/lib/python3.5/site-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "path_to_tf = \"data/tf_records_{}_seed_{}/\".format(hyper_params['input_size'],hyper_params['seed'])\n",
    "log_dir = 'log'\n",
    "config_file = 'customInception.json'\n",
    "\n",
    "with open(config_file) as file: \n",
    "    hyper_params = json.load(file)\n",
    "    \n",
    "    \n",
    "if not os.path.exists(log_dir):\n",
    "    os.mkdir(log_dir)\n",
    "    \n",
    "with open(os.path.join(path_to_tf, 'split.json')) as file: \n",
    "    split = json.load(file)\n",
    "   \n",
    "\n",
    "time = datetime.datetime.today()\n",
    "log_id = '{}_{}h{}min'.format(time.date(), time.hour, time.minute)\n",
    "log_path = os.path.join(log_dir,log_id)\n",
    "i = 0\n",
    "while os.path.exists(log_path):\n",
    "    i = 1\n",
    "    log_id ='{}_{}h{}min_{}'.format(time.date(), time.hour, time.minute, i)\n",
    "    log_path = os.path.join(log_dir,log_id)\n",
    "os.mkdir(log_path)\n",
    "\n",
    "with open(os.path.join(log_path,'split.json'), 'w') as fp:\n",
    "    json.dump(split, fp)\n",
    "with open(os.path.join(log_path,'hyper_params.json'), 'w') as fp:\n",
    "    json.dump(hyper_params, fp)\n",
    "\n",
    "    \n",
    "n_train = len(split['train_id'])\n",
    "n_valid = len(split['valid_id']) \n",
    "train_steps_per_epoch = n_train//hyper_params['batch_size']\n",
    "valid_steps_per_epoch = n_valid//hyper_params['batch_size']\n",
    "\n",
    "train_dataset = input_fn(path_to_tf,'train', batch_size=hyper_params['batch_size'])\n",
    "valid_dataset = input_fn(path_to_tf,'test', batch_size= hyper_params['batch_size'])\n",
    "if hyper_params['model'] == 'resnet':\n",
    "    model = src.model.resnet((hyper_params['input_size'], \n",
    "                              hyper_params['input_size'], \n",
    "                              hyper_params['input_size'], 1), \n",
    "                              32, \n",
    "                              1, \n",
    "                              use3D=True, \n",
    "                              useBatchNorm=hyper_params['batch_norm'])\n",
    "if hyper_params['model'] == 'customInception':\n",
    "    model = src.model.customInception((hyper_params['input_size'], \n",
    "                              hyper_params['input_size'], \n",
    "                              hyper_params['input_size'], 1), \n",
    "                              1, num_filters=64, dense_size=8,\n",
    "                              use3D=True, \n",
    "                              useBatchNorm=hyper_params['batch_norm'])\n",
    "    \n",
    "    \n",
    "adam = Adam(lr=hyper_params['learning_rate'])\n",
    "model.compile(optimizer=adam,\n",
    "              loss= 'mean_squared_error',\n",
    "              metrics=['mean_squared_error'])\n",
    "\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
    "                                  patience=3, min_lr=hyper_params['minimum_learning_rate'], verbose=1)\n",
    "save_best = ModelCheckpoint(os.path.join(log_path,'weights.{epoch:02d}-{val_loss:.2f}.hdf5'), monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "call_backs = [reduce_lr, save_best]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/envs/tfenv/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_dataset, \n",
    "          epochs=hyper_params['n_epochs'], \n",
    "          steps_per_epoch=train_steps_per_epoch, \n",
    "          validation_data=valid_dataset,\n",
    "          validation_steps=valid_steps_per_epoch,\n",
    "          callbacks=call_backs)\n",
    "\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.5 Tensorflow Keras",
   "language": "python",
   "name": "py35-tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
