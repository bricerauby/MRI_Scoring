{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2  \n",
    "import sys\n",
    "sys.path.insert(0,'../')\n",
    "import src.utils\n",
    "import pandas as pd \n",
    "import tqdm\n",
    "import os\n",
    "import multiprocessing\n",
    "import numpy as np \n",
    "import SimpleITK as sitk \n",
    "import matplotlib.pyplot as plt \n",
    "import scipy.misc\n",
    "import multiprocessing\n",
    "import json \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_folder = 'data/Dataset_1/'\n",
    "labels = pd.read_csv(os.path.join(path_to_folder, 'labels.csv'),\n",
    "                     decimal=\",\")\n",
    "list_series = labels.Sequence_id.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_image(original_image, reference_image, T0,\n",
    "                    interpolator = sitk.sitkLinear, default_intensity_value = 0.0):\n",
    "    normalized_image = sitk.Resample(original_image, reference_image, sitk.Transform(T0),\n",
    "                              interpolator, default_intensity_value)\n",
    "    return(normalized_image)\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "def _float_feature(value):\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def preprocess(path_to_folder):\n",
    "    #####Loading the image\n",
    "    seed = 0\n",
    "    size = 112\n",
    "    valid_ratio=0.2\n",
    "    test_ratio=0.2\n",
    "    tf_record_path = 'data/_tf_records_{}_seed_{}'.format(size, seed)\n",
    "    labels = pd.read_csv(os.path.join(path_to_folder, 'labels.csv'),\n",
    "                     decimal=\",\")\n",
    "    list_series = labels.Sequence_id.tolist()\n",
    "    list_arrays = []\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    list_series = np.random.permutation(list_series)\n",
    "    n_test_set = int(len(list_series) * test_ratio)\n",
    "    n_valid_set = int(len(list_series) * valid_ratio)\n",
    "    test_series = list_series[:n_test_set]\n",
    "    valid_series = list_series[n_test_set:n_test_set + n_valid_set]\n",
    "    train_series = list_series[n_test_set + n_valid_set:]\n",
    "    split_dict = {'train_id': list(map(str, train_series)),\n",
    "                  'valid_id': list(map(str, valid_series)),\n",
    "                  'test_id': list(map(str, test_series))}\n",
    "    if not os.path.exists(tf_record_path):\n",
    "        os.makedirs(tf_record_path)\n",
    "    with open(os.path.join(tf_record_path, 'split.json'), 'w') as json_file:\n",
    "        json.dump(split_dict, json_file)\n",
    "    for i,serie in tqdm.tqdm(enumerate(list_series)):\n",
    "        serie_name = str(serie)\n",
    "        serie_path = os.path.join(path_to_folder, serie_name)\n",
    "        infos = {'serie_description': serie_name}\n",
    "        reader = sitk.ImageSeriesReader()\n",
    "        dicom_names = reader.GetGDCMSeriesFileNames(serie_path)\n",
    "        reader.SetFileNames(dicom_names)\n",
    "        image = reader.Execute()\n",
    "        const_voxel_dims = image.GetSize()\n",
    "        infos['dims'] = const_voxel_dims\n",
    "        ConstPixelSpacing = image.GetSpacing()\n",
    "        infos['resolution'] = ConstPixelSpacing\n",
    "        ArrayDicom = sitk.GetArrayFromImage(image).astype('int16')\n",
    "        patient_infos = labels[labels.Sequence_id == int(serie)]\n",
    "        features = {\n",
    "        'age': _int64_feature(patient_infos['age'].iloc[0]),\n",
    "        'Sequence_id': _bytes_feature(str(patient_infos['Sequence_id'].iloc[0])\n",
    "                                      .encode('utf-8')),\n",
    "        'EDSS': _float_feature(float(patient_infos['EDSS'].iloc[0])),\n",
    "        'examination_date': _bytes_feature(patient_infos['examination_date'].iloc[0]\n",
    "                                           .encode('utf-8')),}\n",
    "                \n",
    "        if i == 0:  \n",
    "            dimension = 3\n",
    "            reference_physical_size = np.zeros(dimension)\n",
    "            reference_physical_size[:] = [(sz-1)*spc if sz*spc>mx  else mx for sz,spc,mx in zip(image.GetSize(), image.GetSpacing(), reference_physical_size)]     \n",
    "            reference_origin = np.zeros(dimension)\n",
    "            reference_direction = np.identity(dimension).flatten()\n",
    "            reference_size = [size]*dimension \n",
    "            reference_spacing = [ phys_sz/(sz-1) for sz,phys_sz in zip(reference_size, reference_physical_size) ]\n",
    "            reference_image = sitk.Image(reference_size, image.GetPixelIDValue())\n",
    "            reference_image.SetOrigin(reference_origin)\n",
    "            reference_image.SetSpacing(reference_spacing)\n",
    "            reference_image.SetDirection(reference_direction)\n",
    "            reference_center = np.array(reference_image.TransformContinuousIndexToPhysicalPoint(np.array(reference_image.GetSize())/2.0))\n",
    "\n",
    "        transform = sitk.AffineTransform(dimension)\n",
    "        transform.SetMatrix(image.GetDirection())\n",
    "        transform.SetTranslation(np.array(image.GetOrigin()) - reference_origin)\n",
    "        # Modify the transformation to align the centers of the original and reference image instead of their origins.\n",
    "        centering_transform = sitk.TranslationTransform(dimension)\n",
    "        img_center = np.array(image.TransformContinuousIndexToPhysicalPoint(np.array(image.GetSize())/2.0))\n",
    "        centering_transform.SetOffset(np.array(transform.GetInverse().TransformPoint(img_center) - reference_center))\n",
    "        centered_transform = sitk.Transform(transform)\n",
    "        centered_transform.AddTransform(centering_transform)\n",
    "        normalized_image = resample_image(image, reference_image, transform) \n",
    "        image_array = sitk.GetArrayFromImage(normalized_image).astype('int16')\n",
    "        stringDicom = image_array.tostring()\n",
    "        serializedDicom = _bytes_feature(stringDicom)\n",
    "        features['serie_description'] = (_bytes_feature\n",
    "                                         (serie_name\n",
    "                                          .encode('utf-8')))\n",
    "        h, w, d = normalized_image.GetSize()\n",
    "        features['h'], features['w'], features['d'] = (_int64_feature(h),\n",
    "                                                       _int64_feature(w),\n",
    "                                                       _int64_feature(d))\n",
    "        r_h, r_w, r_d = normalized_image.GetSpacing()\n",
    "        features['r_h'], features['r_w'], features['r_d'] = (_float_feature(r_h),\n",
    "                                                             _float_feature(r_w),\n",
    "                                                             _float_feature(r_d))\n",
    "        features['image_raw'] = serializedDicom\n",
    "                    \n",
    "        example = tf.train.Example(features=tf.train.Features(feature=features))\n",
    "        mode = (serie in train_series) * 'train' + (serie in test_series) * 'test' + (serie in valid_series) * 'valid'\n",
    "        with tf.io.TFRecordWriter(os.path.join(tf_record_path,\n",
    "                                                   '{}_set_{}.tfrecords')\n",
    "                                             .format(mode, serie)) as writer:\n",
    "                writer.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "480it [07:00,  1.14it/s]\n"
     ]
    }
   ],
   "source": [
    "preprocess(path_to_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5 Tensorflow Keras",
   "language": "python",
   "name": "py35-tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
