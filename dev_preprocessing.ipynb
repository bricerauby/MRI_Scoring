{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2  \n",
    "import sys\n",
    "sys.path.insert(0,'../')\n",
    "import src.utils\n",
    "import pandas as pd \n",
    "import tqdm\n",
    "import os\n",
    "import multiprocessing\n",
    "import numpy as np \n",
    "import SimpleITK as sitk \n",
    "import matplotlib.pyplot as plt \n",
    "import scipy.misc\n",
    "import multiprocessing\n",
    "import json \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_folder = 'data/Dataset_1/'\n",
    "labels = pd.read_csv(os.path.join(path_to_folder, 'labels.csv'),\n",
    "                     decimal=\",\")\n",
    "list_series = labels.Sequence_id.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_based_crop(image):\n",
    "    \"\"\"\n",
    "    Use Otsu's threshold estimator to separate background and foreground. In medical imaging the background is\n",
    "    usually air. Then crop the image using the foreground's axis aligned bounding box.\n",
    "    Args:\n",
    "        image (SimpleITK image): An image where the anatomy and background intensities form a bi-modal distribution\n",
    "                                 (the assumption underlying Otsu's method.)\n",
    "    Return:\n",
    "        Cropped image based on foreground's axis aligned bounding box.                                 \n",
    "    \"\"\"\n",
    "    # Set pixels that are in [min_intensity,otsu_threshold] to inside_value, values above otsu_threshold are\n",
    "    # set to outside_value. The anatomy has higher intensity values than the background, so it is outside.\n",
    "    inside_value = 0\n",
    "    outside_value = 255\n",
    "    label_shape_filter = sitk.LabelShapeStatisticsImageFilter()\n",
    "    label_shape_filter.Execute( sitk.OtsuThreshold(image, inside_value, outside_value) )\n",
    "    bounding_box = label_shape_filter.GetBoundingBox(outside_value)\n",
    "    # The bounding box's first \"dim\" entries are the starting index and last \"dim\" entries the size\n",
    "    return sitk.RegionOfInterest(image, bounding_box[int(len(bounding_box)/2):], bounding_box[0:int(len(bounding_box)/2)])\n",
    "    \n",
    "    \n",
    "def resample_image(original_image, reference_image, T0,\n",
    "                    interpolator = sitk.sitkLinear, default_intensity_value = 0.0):\n",
    "    normalized_image = sitk.Resample(original_image, reference_image, sitk.Transform(T0),\n",
    "                              interpolator, default_intensity_value)\n",
    "    return(normalized_image)\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "def _float_feature(value):\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def preprocess(path_to_folder, normalization = 'mean'):\n",
    "    #####Loading the image\n",
    "    seed = 0\n",
    "    size = 160\n",
    "    valid_ratio=0.2\n",
    "    test_ratio=0.2\n",
    "    reference_spacing = [1,1,1]\n",
    "    tf_record_path = 'data/_tf_records_{}_seed_{}'.format(size, seed)\n",
    "    labels = pd.read_csv(os.path.join(path_to_folder, 'labels.csv'),\n",
    "                     decimal=\",\")\n",
    "    with open('ignored.json') as json_file:\n",
    "        ignored_dict = json.load(json_file)  \n",
    "    list_series = labels.Sequence_id.tolist()\n",
    "    np.random.seed(seed)\n",
    "    list_series = [serie for serie in list_series  if not str(serie) in ignored_dict[\"ignored\"]]  \n",
    "    list_series = np.random.permutation(list_series)\n",
    "    \n",
    "    n_test_set = int(len(list_series) * test_ratio)\n",
    "    n_valid_set = int(len(list_series) * valid_ratio)\n",
    "    test_series = list_series[:n_test_set]\n",
    "    valid_series = list_series[n_test_set:n_test_set + n_valid_set]\n",
    "    train_series = list_series[n_test_set + n_valid_set:]\n",
    "    split_dict = {'train_id': list(map(str, train_series)),\n",
    "                  'valid_id': list(map(str, valid_series)),\n",
    "                  'test_id': list(map(str, test_series))}\n",
    "    if not os.path.exists(tf_record_path):\n",
    "        os.makedirs(tf_record_path)\n",
    "    with open(os.path.join(tf_record_path, 'split.json'), 'w') as json_file:\n",
    "        json.dump(split_dict, json_file)\n",
    "    for i,serie in tqdm.tqdm(enumerate(list_series)):\n",
    "        serie_name = str(serie)\n",
    "        serie_path = os.path.join(path_to_folder, serie_name)\n",
    "        infos = {'serie_description': serie_name}\n",
    "        reader = sitk.ImageSeriesReader()\n",
    "        dicom_names = reader.GetGDCMSeriesFileNames(serie_path)\n",
    "        reader.SetFileNames(dicom_names)\n",
    "        image = reader.Execute()\n",
    "        const_voxel_dims = image.GetSize()\n",
    "        infos['dims'] = const_voxel_dims\n",
    "        ConstPixelSpacing = image.GetSpacing()\n",
    "        infos['resolution'] = ConstPixelSpacing\n",
    "        patient_infos = labels[labels.Sequence_id == int(serie)]\n",
    "        features = {\n",
    "        'age': _int64_feature(patient_infos['age'].iloc[0]),\n",
    "        'Sequence_id': _bytes_feature(str(patient_infos['Sequence_id'].iloc[0])\n",
    "                                      .encode('utf-8')),\n",
    "        'EDSS': _float_feature(float(patient_infos['EDSS'].iloc[0])),\n",
    "        'examination_date': _bytes_feature(patient_infos['examination_date'].iloc[0]\n",
    "                                           .encode('utf-8')),}\n",
    "                \n",
    "        serie_name = str(serie)\n",
    "        serie_path = os.path.join(path_to_folder, serie_name)\n",
    "        infos = {'serie_description': serie_name}\n",
    "        reader = sitk.ImageSeriesReader()\n",
    "        dicom_names = reader.GetGDCMSeriesFileNames(serie_path)\n",
    "        reader.SetFileNames(dicom_names)\n",
    "        image = reader.Execute()\n",
    "        dimension = 3 \n",
    "        reference_origin = np.zeros(dimension)\n",
    "        reference_direction = np.identity(dimension).flatten()\n",
    "        reference_size = [300]*dimension \n",
    "        \n",
    "        reference_image = sitk.Image(reference_size, image.GetPixelIDValue())\n",
    "        reference_image.SetOrigin(reference_origin)\n",
    "        reference_image.SetSpacing(reference_spacing)\n",
    "        reference_image.SetDirection(reference_direction)\n",
    "        reference_center = np.array(reference_image.TransformContinuousIndexToPhysicalPoint(np.array(reference_image.GetSize())/2.0))\n",
    "\n",
    "        transform = sitk.AffineTransform(dimension)\n",
    "        transform.SetMatrix(image.GetDirection())\n",
    "        transform.SetTranslation(np.array(image.GetOrigin()) - reference_origin)\n",
    "        centering_transform = sitk.TranslationTransform(dimension)\n",
    "        img_center = np.array(image.TransformContinuousIndexToPhysicalPoint(np.array(image.GetSize())/2.0))\n",
    "        centering_transform.SetOffset(np.array(transform.GetInverse().TransformPoint(img_center) - reference_center))\n",
    "        centered_transform = sitk.Transform(transform)\n",
    "        centered_transform.AddTransform(centering_transform)\n",
    "        aug_transform = sitk.AffineTransform(dimension)\n",
    "        aug_transform.SetCenter(reference_center)\n",
    "        aug_transform.SetMatrix(image.GetDirection())\n",
    "        T_all = sitk.Transform(centered_transform)\n",
    "        T_all.AddTransform(aug_transform.GetInverse())\n",
    "        aug_image = sitk.Resample(image, reference_image, T_all,  sitk.sitkLinear,0.0)\n",
    "        bb = threshold_based_crop(aug_image)\n",
    "        image_array = np.swapaxes(sitk.GetArrayFromImage(bb).astype('int16'),0,2)[-size:,-size:,-size:]\n",
    "        if normalization == 'mean':\n",
    "            mean_arr = np.mean(image_array) \n",
    "            max_arr = np.amax(image_array)\n",
    "            image_array = np.clip((image_array - mean_arr) / max_arr, 0, 1)\n",
    "        elif normalization == 'min':\n",
    "            min_arr = np.amin(image_array) \n",
    "            max_arr = np.amax(image_array)\n",
    "            image_array = np.clip((image_array - min_arr) / max_arr , 0, 1)\n",
    "        elif normalization == 'clahe':\n",
    "            raise NotImplemented\n",
    "        stringDicom = image_array.tostring()\n",
    "        serializedDicom = _bytes_feature(stringDicom)\n",
    "        features['serie_description'] = (_bytes_feature\n",
    "                                         (serie_name\n",
    "                                          .encode('utf-8')))\n",
    "        h, w, d = array.shape\n",
    "        features['h'], features['w'], features['d'] = (_int64_feature(h),\n",
    "                                                       _int64_feature(w),\n",
    "                                                       _int64_feature(d))\n",
    "        r_h, r_w, r_d = image.GetSpacing()\n",
    "        features['r_h'], features['r_w'], features['r_d'] = (_float_feature(r_h),\n",
    "                                                             _float_feature(r_w),\n",
    "                                                             _float_feature(r_d))\n",
    "        features['image_raw'] = serializedDicom\n",
    "                    \n",
    "        example = tf.train.Example(features=tf.train.Features(feature=features))\n",
    "        mode = (serie in train_series) * 'train' + (serie in test_series) * 'test' + (serie in valid_series) * 'valid'\n",
    "        with tf.io.TFRecordWriter(os.path.join(tf_record_path,\n",
    "                                                   '{}_set_{}.tfrecords')\n",
    "                                             .format(mode, serie)) as writer:\n",
    "                writer.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "480it [07:00,  1.14it/s]\n"
     ]
    }
   ],
   "source": [
    "preprocess(path_to_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
